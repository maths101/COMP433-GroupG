{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvi8mwzsXvUbgpv24yQEwj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Code Overview: Importing Libraries and Setting Up the Environment"],"metadata":{"id":"CVc10udCZmIE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nRoskwniWErZ"},"outputs":[],"source":["# Import Standard Libraries\n","import os\n","import tarfile\n","import time\n","import random\n","import glob\n","from PIL import Image\n","from collections import Counter\n","from tqdm.auto import tqdm\n","import pandas as pd\n","\n","#Plotting\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","\n","# Import PyTorch Libraries\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler\n","import torchvision.transforms as transforms\n","from torchvision.transforms.functional import to_pil_image\n","from torchvision import datasets\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# Install and Import timm for transformer architecture\n","!pip install timm -q\n","import timm\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Labeled Data Extraction"],"metadata":{"id":"g3nag_dLZ4yh"}},{"cell_type":"code","source":["# Define the source and destination folder paths\n","def extract_all_tar_xz(source_folder_path, destination_folder_path):\n","\n","    # Iterate through all files in the source folder\n","    for file_name in os.listdir(source_folder_path):\n","        if file_name.endswith('.tar.xz'):\n","            tar_file_path = os.path.join(source_folder_path, file_name)\n","\n","            print(f\"Extracting {file_name} into {destination_folder_path}...\")\n","\n","            # Extract the .tar.xz file directly into the destination folder\n","            with tarfile.open(tar_file_path, 'r:xz') as tar:\n","                tar.extractall(path=destination_folder_path)\n","\n","            print(f\"Finished extracting {file_name}.\")\n","\n","    print(\"All .tar.xz files have been successfully extracted.\")\n","\n","extract_all_tar_xz('/content/drive/MyDrive/Test_Data', '/content/Labeled_Data_4_Class')"],"metadata":{"id":"viiXI_vNWJKz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preparing Labelled Datasets and DataLoaders"],"metadata":{"id":"EmeO7OEVZ6cF"}},{"cell_type":"code","source":["# Function to remove hidden folders\n","def remove_hidden_folders(folder_path):\n","    for root, dirs, _ in os.walk(folder_path):\n","        for dir_name in dirs:\n","            if dir_name.startswith('.'):  # Hidden folder detection\n","                full_path = os.path.join(root, dir_name)\n","                print(f\"Removing hidden folder: {full_path}\")\n","                os.rmdir(full_path)\n","\n","from collections import defaultdict\n","import torch\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Subset\n","import random\n","\n","def prepare_balanced_test_set(data_dir, batch_size=32, num_samples_per_class=100):\n","\n","    remove_hidden_folders(data_dir)\n","\n","    # Define transformations for preprocessing\n","    data_transforms = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n","    ])\n","\n","    # Load the dataset\n","    dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)\n","\n","    # Group indices by class\n","    class_to_indices = defaultdict(list)\n","    for idx, (_, class_label) in enumerate(dataset):\n","        class_to_indices[class_label].append(idx)\n","\n","    # Determine the number of samples to pick from each class\n","    num_classes = len(class_to_indices)\n","    samples_per_class = num_samples_per_class // num_classes\n","    selected_indices = []\n","\n","    for class_label, indices in class_to_indices.items():\n","        if len(indices) >= samples_per_class:\n","            selected_indices.extend(random.sample(indices, samples_per_class))\n","        else:\n","            selected_indices.extend(indices)  # Use all samples if insufficient\n","\n","    # Shuffle selected indices to avoid ordering issues\n","    random.shuffle(selected_indices)\n","\n","    # Create the test subset\n","    test_dataset = Subset(dataset, selected_indices)\n","\n","    # Create the DataLoader\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","    # Print class distribution in the test set\n","    class_counts = defaultdict(int)\n","    for _, label in test_dataset:\n","        class_counts[label] += 1\n","    print(\"Class distribution in the test set:\", dict(class_counts))\n","\n","    return test_loader, dataset.class_to_idx\n","\n","def print_batch_info(train_loader):\n","    for images, labels in train_loader:\n","        print(f\"Batch size: {images.size()}, Labels: {labels}\")\n","        break"],"metadata":{"id":"Z3C-VBbzWNcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loader_4_Class, class_to_idx_4_Class = prepare_balanced_test_set('/content/Labeled_Data_4_Class')\n","print_batch_info(test_loader_4_Class)\n","print(class_to_idx_4_Class)"],"metadata":{"id":"JeHEXmWiWRO-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Load model and classification head"],"metadata":{"id":"3SuUB8i4Z8pd"}},{"cell_type":"code","source":["# Define parameters\n","def intialize_model(checkpoint_path, num_classes, device):\n","\n","    # Load the checkpoint\n","    if os.path.exists(checkpoint_path):\n","        print(f\"Loading checkpoint from: {checkpoint_path}\")\n","        checkpoint = torch.load(checkpoint_path, map_location=device)\n","\n","        # Load the pre-trained backbone\n","        backbone = timm.create_model('vit_tiny_patch16_224', pretrained=True)\n","\n","        # Recreate the model architecture to match the saved checkpoint\n","        in_dim = backbone.head.in_features\n","\n","        classification_head = nn.Sequential(\n","            nn.Linear(in_dim, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","        # Use the saved classification head\n","        backbone.head = classification_head\n","        backbone = backbone.to(device)\n","\n","        # Load the saved state dict\n","        backbone.load_state_dict(checkpoint['model_state_dict'], strict=True)\n","        print(f\"Model loaded successfully with the saved head from {checkpoint_path}\")\n","    else:\n","        print(f\"Checkpoint not found at {checkpoint_path}. Starting with a fresh model.\")\n","\n","    # Test the loaded model with dummy data\n","    dummy_input = torch.randn(1, 3, 224, 224).to(device)\n","    output = backbone(dummy_input)\n","    print(\"Output shape:\", output.shape)  # Should match [1, num_classes]\n","\n","    return backbone\n","\n","backbone_4_class = intialize_model('/content/checkpoints/final_model_tiny_4_Class.pth', 4, device)"],"metadata":{"id":"URNrDAMkWWM5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Class weights for criterion"],"metadata":{"id":"YLzuW514aB7Y"}},{"cell_type":"code","source":["# Calculate class weights for imbalanced datasets\n","def get_class_weights(train_loader):\n","    class_counts = Counter([label for _, label in train_loader.dataset])\n","    class_weights = [1.0 / class_counts[c] for c in range(len(class_counts))]\n","    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n","\n","    # Convert class weights to a tensor\n","    class_weights = torch.tensor([class_weights[i] for i in range(len(class_counts))], dtype=torch.float).to(device)\n","\n","    # Output the class counts\n","    print(\"Class Counts:\", class_counts)\n","    print(\"Class Weights:\", class_weights)\n","\n","    return class_weights"],"metadata":{"id":"f4nB5irfWZUT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Validate model on test set"],"metadata":{"id":"I71wCPPOaDVA"}},{"cell_type":"code","source":["def validate_model(backbone, test_loader, device, class_weights, num_classes):\n","\n","    backbone.eval()\n","    total_valid_loss = 0\n","    correct_valid = 0\n","    total_valid = 0\n","\n","    criterion = nn.CrossEntropyLoss(weight=class_weights)\n","    optimizer = optim.Adam(backbone.head.parameters(), lr=0.001, weight_decay=1e-5)\n","\n","    all_valid_labels = []\n","    all_valid_predictions = []\n","    huron_tiny_7_classes_metrics = {}\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = backbone(images)\n","            loss = criterion(outputs, labels)\n","\n","            # Track validation loss and accuracy\n","            total_valid_loss += loss.item()\n","            _, predicted = torch.max(outputs, 1)\n","            correct_valid += (predicted == labels).sum().item()\n","            total_valid += labels.size(0)\n","\n","            # Store predictions and labels for metrics\n","            all_valid_labels.extend(labels.cpu().numpy())\n","            all_valid_predictions.extend(predicted.cpu().numpy())\n","\n","    valid_loss = total_valid_loss / len(test_loader)\n","    valid_accuracy = correct_valid / total_valid * 100\n","    valid_precision = precision_score(all_valid_labels, all_valid_predictions, average='weighted')\n","    valid_recall = recall_score(all_valid_labels, all_valid_predictions, average='weighted')\n","    valid_f1 = f1_score(all_valid_labels, all_valid_predictions, average='weighted')\n","\n","    from sklearn.metrics import confusion_matrix\n","    import seaborn as sns\n","    import matplotlib.pyplot as plt\n","\n","    # Calculate the confusion matrix\n","    conf_matrix = confusion_matrix(all_valid_labels, all_valid_predictions)\n","\n","    # Plot the confusion matrix\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","    metric_dict = {\n","        'model_name': f'Huron Tiny {num_classes} Classes',\n","        'valid_accuracy': valid_accuracy,\n","        'valid_precision': valid_precision,\n","        'valid_recall': valid_recall,\n","        'valid_f1': valid_f1\n","    }\n","\n","    print(\"Final Metrics:\", metric_dict)\n","\n","    return metric_dict\n","\n","huron_tiny_4_classes_metrics = validate_model(backbone_4_class, test_loader_4_Class, device, get_class_weights(test_loader_4_Class), 4)"],"metadata":{"id":"vfPe-5xlWcEL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Download metrics as excel sheet"],"metadata":{"id":"GmzX42naaGHb"}},{"cell_type":"code","source":["df = pd.DataFrame(huron_tiny_4_classes_metrics)\n","\n","# Display the table\n","print(\"\\nMetrics Table:\")\n","print(df)\n","\n","# Save the DataFrame as an Excel fil\n","output_file = 'model_metrics.xlsx'\n","df.to_excel(output_file, index=False)"],"metadata":{"id":"FWWgkOKMWh44"},"execution_count":null,"outputs":[]}]}